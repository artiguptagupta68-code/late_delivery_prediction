{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L4RaufNV8ifL",
        "outputId": "3e0446e1-425d-40af-be8e-ed5b42ddaf62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.3.2)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Environment setup check completed. Required libraries are installed.\n",
            "... Loading or creating simulated historical dataset ...\n",
            "Dataset created with 500 samples. Target variable 'is_late' distribution:\n",
            "is_late\n",
            "1    0.5\n",
            "0    0.5\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "==================================================\n",
            "\n",
            "Preprocessing pipeline (Scaling + One-Hot Encoding) created.\n",
            "Data split: Train size: 400, Test size: 100\n",
            "\n",
            "==================================================\n",
            "\n",
            "... Training XGBoost model ...\n",
            "Training completed in 0.14 seconds.\n",
            "\n",
            "--- Model Evaluation (Test Set) ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.58      0.57        50\n",
            "           1       0.57      0.56      0.57        50\n",
            "\n",
            "    accuracy                           0.57       100\n",
            "   macro avg       0.57      0.57      0.57       100\n",
            "weighted avg       0.57      0.57      0.57       100\n",
            "\n",
            "ROC AUC Score: 0.5356\n",
            "Model saved as 'late_delivery_predictor_model.pkl'.\n",
            "\n",
            "==================================================\n",
            "\n",
            "\n",
            "--- Conceptual Streamlit Dashboard Code (omitted) ---\n",
            "To run the full dashboard, save the Streamlit app separately (app.py).\n",
            "\n",
            "--- Real-Time Prediction Demonstration ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3001421445.py:170: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  'Order_Placed_Time': pd.to_datetime(pd.date_range('2025-01-01', periods=500, freq='4H')),\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [10:37:14] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weather fetched successfully: Clear, 25.15Â°C\n",
            "Live traffic data successfully retrieved from HERE API.\n",
            "\n",
            "--- Prediction Result ---\n",
            "Distance: 14.79 km\n",
            "Estimated Traffic-Adjusted Travel Time: 53.5 min\n",
            "Current Traffic Density (categorical): Jam\n",
            "Weather: Clear, temp: 25.15Â°C, wind_speed: 3.41\n",
            "Probability of Being Late: 88.25%\n",
            "Conclusion: High risk of late delivery (Predicted Late).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6b75755a-3136-4113-a520-64265a1f8f82\", \"late_delivery_predictor_model.pkl\", 518700)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# --- Cell 1: Setup and Requirements ---\n",
        "\n",
        "!pip install pandas numpy scikit-learn xgboost requests joblib\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "import joblib\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# --- Configuration (UPDATE THIS!) ---\n",
        "# You need a key from OpenWeatherMap or a similar service to fetch real-time data.\n",
        "WEATHER_API_KEY = \"5197fc88f5f846ee7566eb28d403c91f\"\n",
        "\n",
        "# Added from app.py: HERE API key and placeholder check\n",
        "HERE_API_KEY = \"9JI9eOC0auXHPTmtQ5SohrGPp4WjOaq90TRCjfa-Czw\"\n",
        "PLACEHOLDER_CHECK = \"PASTE_YOUR_API_KEY_HERE\"\n",
        "\n",
        "THRESHOLD_MIN = 10  # Delivery is \"Late\" if actual time > estimated time + THRESHOLD_MIN\n",
        "\n",
        "def setup_environment():\n",
        "    \"\"\"Confirms environment setup.\"\"\"\n",
        "    print(\"Environment setup check completed. Required libraries are installed.\")\n",
        "\n",
        "# Run setup\n",
        "setup_environment()\n",
        "\n",
        "\n",
        "# --- Cell 2: Helper Functions ---\n",
        "\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    \"\"\"Calculate the great circle distance in km between two points on the earth.\"\"\"\n",
        "    R = 6371  # Earth radius in kilometers\n",
        "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
        "    dlon = lon2 - lon1\n",
        "    dlat = lat2 - lat1\n",
        "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
        "    c = 2 * np.arcsin(np.sqrt(a))\n",
        "    return R * c\n",
        "\n",
        "def fetch_realtime_weather(latitude, longitude, api_key):\n",
        "    \"\"\"Fetches real-time weather data for a given location using OpenWeatherMap API.\n",
        "    Returns (temp, weather_main, wind_speed). Uses fallback on failure.\"\"\"\n",
        "    if not api_key or api_key.strip() == \"\" or api_key == \"YOUR_OPENWEATHERMAP_API_KEY\":\n",
        "        print(\"Warning: Weather API Key missing or placeholder. Using fallback weather values.\")\n",
        "        return 25.0, 'Clear', 5.0  # Return fallback values for simulation\n",
        "\n",
        "    try:\n",
        "        url = f\"http://api.openweathermap.org/data/2.5/weather?lat={latitude}&lon={longitude}&appid={api_key}&units=metric\"\n",
        "        response = requests.get(url, timeout=6)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        temp = data['main']['temp']\n",
        "        weather_main = data['weather'][0]['main']\n",
        "        wind_speed = data['wind'].get('speed', np.nan)\n",
        "\n",
        "        print(f\"Weather fetched successfully: {weather_main}, {temp}Â°C\")\n",
        "        return temp, weather_main, wind_speed\n",
        "\n",
        "    except requests.exceptions.HTTPError as e:\n",
        "        # If auth error or other HTTP errors occur, fallback\n",
        "        try:\n",
        "            status = response.status_code\n",
        "            print(f\"Weather API HTTP Error ({status}): {e}. Using fallback.\")\n",
        "        except Exception:\n",
        "            print(f\"Weather API HTTP Error: {e}. Using fallback.\")\n",
        "        return np.nan, 'Unknown', np.nan\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching weather data: {e}. Using fallback.\")\n",
        "        return np.nan, 'Unknown', np.nan\n",
        "\n",
        "\n",
        "def fetch_coordinates(location_name, api_key):\n",
        "    \"\"\"Forward geocoding: returns (lat, lon, display_name) using OpenWeatherMap geocoding endpoint.\n",
        "    If not possible, returns (None, None, None).\"\"\"\n",
        "    if not api_key or not location_name:\n",
        "        return None, None, None\n",
        "    try:\n",
        "        url = f\"http://api.openweathermap.org/geo/1.0/direct?q={location_name}&limit=1&appid={api_key}\"\n",
        "        response = requests.get(url, timeout=5)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if data:\n",
        "            loc = data[0]\n",
        "            lat = loc.get('lat')\n",
        "            lon = loc.get('lon')\n",
        "            display_name = f\"{loc.get('name', 'N/A')}, {loc.get('country', 'N/A')}\"\n",
        "            return lat, lon, display_name\n",
        "        else:\n",
        "            print(f\"Warning: Could not find coordinates for: {location_name}\")\n",
        "            return None, None, None\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Geocoding Error: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "\n",
        "def fetch_live_traffic_time(rest_lat, rest_lon, del_lat, del_lon, api_key):\n",
        "    \"\"\"\n",
        "    Call HERE Routing API with traffic enabled (if API key present).\n",
        "    Returns (estimated_travel_time_traffic_adjusted_min, base_travel_time_min) in minutes.\n",
        "    If API unavailable or key missing/placeholder, returns (None, None) to indicate fallback simulation should be used.\n",
        "    \"\"\"\n",
        "    if not api_key or api_key == PLACEHOLDER_CHECK:\n",
        "        # No real traffic available; caller should fallback to simulation\n",
        "        return None, None\n",
        "\n",
        "    try:\n",
        "        url = \"https://router.hereapi.com/v8/routes\"\n",
        "        origin_coords = f\"{rest_lat},{rest_lon}\"\n",
        "        destination_coords = f\"{del_lat},{del_lon}\"\n",
        "        params = {\n",
        "            'transportMode': 'car',\n",
        "            'origin': origin_coords,\n",
        "            'destination': destination_coords,\n",
        "            'routingMode': 'fast',\n",
        "            'trafficMode': 'realtime',\n",
        "            'return': 'summary',\n",
        "            'apiKey': api_key\n",
        "        }\n",
        "        response = requests.get(url, params=params, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        if data.get('routes') and data['routes'][0].get('sections'):\n",
        "            summary = data['routes'][0]['sections'][0]['summary']\n",
        "            traffic_duration_sec = summary.get('duration')\n",
        "            base_duration_sec = summary.get('baseDuration')\n",
        "            if traffic_duration_sec is None or base_duration_sec is None:\n",
        "                print(\"HERE API response missing duration data. Falling back to simulation.\")\n",
        "                return None, None\n",
        "            traffic_duration_min = traffic_duration_sec / 60.0\n",
        "            base_travel_time_min = base_duration_sec / 60.0\n",
        "            print(\"Live traffic data successfully retrieved from HERE API.\")\n",
        "            return traffic_duration_min, base_travel_time_min\n",
        "        else:\n",
        "            print(\"HERE API failed to find route. Falling back to simulation.\")\n",
        "            return None, None\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"HERE API Connection Error: {e}. Falling back to simulation.\")\n",
        "        return None, None\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing HERE response: {e}. Falling back to simulation.\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "# --- Cell 3: Dataset Creation and Feature Engineering ---\n",
        "\n",
        "def get_or_create_dataset():\n",
        "    \"\"\"Simulates loading and initial feature engineering on a historical dataset.\"\"\"\n",
        "    print(\"... Loading or creating simulated historical dataset ...\")\n",
        "\n",
        "    # 1. Simulate Historical Data\n",
        "    np.random.seed(42)  # For reproducibility\n",
        "    data = {\n",
        "        'Order_ID': range(500),  # Increased sample size\n",
        "        'Restaurant_lat': np.random.uniform(28.5, 28.7, 500),\n",
        "        'Restaurant_lon': np.random.uniform(77.1, 77.3, 500),\n",
        "        'Delivery_lat': np.random.uniform(28.5, 28.7, 500),\n",
        "        'Delivery_lon': np.random.uniform(77.1, 77.3, 500),\n",
        "        'Order_Placed_Time': pd.to_datetime(pd.date_range('2025-01-01', periods=500, freq='4H')),\n",
        "        'Initial_Estimate_Min': np.random.randint(25, 45, 500),\n",
        "        'Actual_Delivery_Time_Min': np.random.randint(20, 70, 500),\n",
        "        'preparation_time_min': np.random.randint(10, 30, 500),\n",
        "        'restaurant_rating': np.random.uniform(3.0, 5.0, 500).round(1),\n",
        "        'delivery_person_rating': np.random.uniform(4.0, 5.0, 500).round(1),\n",
        "        'Road_Traffic_Density': np.random.choice(['Low', 'Medium', 'High', 'Jam'], 500, p=[0.4, 0.3, 0.2, 0.1]),\n",
        "        'Weather_Condition': np.random.choice(['Clear', 'Rainy', 'Foggy', 'Stormy'], 500, p=[0.7, 0.2, 0.05, 0.05])\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # 2. Feature Engineering\n",
        "    df['delivery_distance_km'] = haversine(\n",
        "        df['Restaurant_lat'], df['Restaurant_lon'],\n",
        "        df['Delivery_lat'], df['Delivery_lon']\n",
        "    )\n",
        "\n",
        "    # Time-based features\n",
        "    df['order_hour'] = df['Order_Placed_Time'].dt.hour\n",
        "    df['day_of_week'] = df['Order_Placed_Time'].dt.day_name()\n",
        "\n",
        "    # Cyclic features for hour\n",
        "    df['sin_hour'] = np.sin(2 * np.pi * df['order_hour'] / 24)\n",
        "    df['cos_hour'] = np.cos(2 * np.pi * df['order_hour'] / 24)\n",
        "\n",
        "    # Target Variable\n",
        "    df['is_late'] = np.where(\n",
        "        df['Actual_Delivery_Time_Min'] > (df['Initial_Estimate_Min'] + THRESHOLD_MIN),\n",
        "        1,\n",
        "        0\n",
        "    )\n",
        "\n",
        "    # Add simulated weather for training data (as historical data won't use the live API)\n",
        "    df['current_temp_c'] = np.random.uniform(15, 35, 500)\n",
        "\n",
        "    final_features = [\n",
        "        'delivery_distance_km', 'preparation_time_min', 'restaurant_rating',\n",
        "        'delivery_person_rating', 'Road_Traffic_Density', 'Weather_Condition',\n",
        "        'sin_hour', 'cos_hour'\n",
        "    ]\n",
        "\n",
        "    df_train = df[final_features + ['current_temp_c', 'is_late']].copy()\n",
        "\n",
        "    print(f\"Dataset created with {len(df_train)} samples. Target variable 'is_late' distribution:\")\n",
        "    print(df_train['is_late'].value_counts(normalize=True))\n",
        "    return df_train, final_features\n",
        "\n",
        "\n",
        "# --- Cell 4: Preprocessing Functions ---\n",
        "\n",
        "def create_preprocessing_pipeline(feature_list):\n",
        "    \"\"\"Creates a scikit-learn ColumnTransformer for preprocessing.\"\"\"\n",
        "\n",
        "    numeric_features = [\n",
        "        'delivery_distance_km', 'preparation_time_min', 'restaurant_rating',\n",
        "        'delivery_person_rating', 'current_temp_c', 'sin_hour', 'cos_hour'\n",
        "    ]\n",
        "\n",
        "    categorical_features = [\n",
        "        'Road_Traffic_Density', 'Weather_Condition'\n",
        "    ]\n",
        "\n",
        "    # Create preprocessing steps\n",
        "    numeric_transformer = Pipeline(steps=[\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "\n",
        "    # Combine transformers\n",
        "    # Only include features present in feature_list (plus current_temp_c)\n",
        "    num_cols = [f for f in numeric_features if (f in feature_list) or (f == 'current_temp_c')]\n",
        "    cat_cols = [f for f in categorical_features if f in feature_list]\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, num_cols),\n",
        "            ('cat', categorical_transformer, cat_cols)\n",
        "        ],\n",
        "        remainder='passthrough'\n",
        "    )\n",
        "\n",
        "    print(\"Preprocessing pipeline (Scaling + One-Hot Encoding) created.\")\n",
        "    return preprocessor  # FIX: return the actual preprocessor object\n",
        "\n",
        "\n",
        "def perform_preprocessing(df_train, feature_list, preprocessor):\n",
        "    \"\"\"Splits data and prepares for the full pipeline.\"\"\"\n",
        "\n",
        "    # Include 'current_temp_c' in X for training as it's a numeric feature\n",
        "    X = df_train[feature_list + ['current_temp_c']].copy()\n",
        "    y = df_train['is_late']\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    print(f\"Data split: Train size: {len(X_train)}, Test size: {len(X_test)}\")\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "# --- Cell 5: Model Training, Evaluation, and Saving ---\n",
        "\n",
        "def train_and_evaluate_model(X_train, X_test, y_train, y_test, preprocessor):\n",
        "    \"\"\"Defines, trains, and evaluates the final ML pipeline.\"\"\"\n",
        "\n",
        "    # Model Choice: XGBoost Hyperparameters\n",
        "    XGB_PARAMS = {\n",
        "        'objective': 'binary:logistic',\n",
        "        'n_estimators': 300,\n",
        "        'learning_rate': 0.05,\n",
        "        'max_depth': 5,\n",
        "        'subsample': 0.7,\n",
        "        'colsample_bytree': 0.7,\n",
        "        'random_state': 42,\n",
        "        'use_label_encoder': False,\n",
        "        'eval_metric': 'logloss'\n",
        "    }\n",
        "\n",
        "    model = XGBClassifier(**XGB_PARAMS)\n",
        "\n",
        "    # Create the full ML pipeline\n",
        "    full_pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', model)\n",
        "    ])\n",
        "\n",
        "    print(\"... Training XGBoost model ...\")\n",
        "    start_time = time.time()\n",
        "    full_pipeline.fit(X_train, y_train)\n",
        "    end_time = time.time()\n",
        "    print(f\"Training completed in {end_time - start_time:.2f} seconds.\")\n",
        "\n",
        "    # Evaluation\n",
        "    y_pred = full_pipeline.predict(X_test)\n",
        "    y_proba = full_pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    print(\"\\n--- Model Evaluation (Test Set) ---\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(f\"ROC AUC Score: {roc_auc_score(y_test, y_proba):.4f}\")\n",
        "\n",
        "    # Save the model\n",
        "    joblib.dump(full_pipeline, 'late_delivery_predictor_model.pkl')\n",
        "    print(\"Model saved as 'late_delivery_predictor_model.pkl'.\")\n",
        "\n",
        "    return full_pipeline\n",
        "\n",
        "\n",
        "# --- Cell 6: Real-Time Dashboard (Conceptual & Demonstration) ---\n",
        "\n",
        "def create_real_time_dashboard(model_pipeline, features):\n",
        "    \"\"\"\n",
        "    Provides the conceptual code for the Streamlit dashboard and demonstrates a real-time prediction using the saved model.\n",
        "    This function performs a real-time prediction demonstration (not a full Streamlit app).\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n--- Conceptual Streamlit Dashboard Code (omitted) ---\")\n",
        "    print(\"To run the full dashboard, save the Streamlit app separately (app.py).\")\n",
        "    print(\"\\n--- Real-Time Prediction Demonstration ---\")\n",
        "\n",
        "    # 1. Define a New Order (Input Data)\n",
        "    NEW_ORDER_DATA = {\n",
        "        'Restaurant_lat': 28.60,\n",
        "        'Restaurant_lon': 77.15,\n",
        "        'Delivery_lat': 28.70,\n",
        "        'Delivery_lon': 77.25,\n",
        "        'preparation_time_min': 25,\n",
        "        'restaurant_rating': 4.2,\n",
        "        'delivery_person_rating': 4.9,\n",
        "    }\n",
        "\n",
        "    # 2. Feature Engineering\n",
        "    current_time = pd.Timestamp.now(tz='Asia/Kolkata')\n",
        "    order_hour = current_time.hour\n",
        "\n",
        "    delivery_distance_km = haversine(\n",
        "        NEW_ORDER_DATA['Restaurant_lat'], NEW_ORDER_DATA['Restaurant_lon'],\n",
        "        NEW_ORDER_DATA['Delivery_lat'], NEW_ORDER_DATA['Delivery_lon']\n",
        "    )\n",
        "\n",
        "    # Simulate Real-time Dynamic Features\n",
        "    temp, weather_main, wind_speed = fetch_realtime_weather(\n",
        "        NEW_ORDER_DATA['Delivery_lat'],\n",
        "        NEW_ORDER_DATA['Delivery_lon'],\n",
        "        WEATHER_API_KEY\n",
        "    )\n",
        "\n",
        "    # Traffic Density Simulation based on time (for demonstration)\n",
        "    # Use multipliers and labels adopted from app.py\n",
        "    if 17 <= order_hour <= 21:\n",
        "        traffic_multiplier_sim = 1.67\n",
        "        traffic_label_sim = 'Jam'\n",
        "    elif 12 <= order_hour <= 14:\n",
        "        traffic_multiplier_sim = 1.33\n",
        "        traffic_label_sim = 'High'\n",
        "    elif 8 <= order_hour <= 10:\n",
        "        traffic_multiplier_sim = 1.18\n",
        "        traffic_label_sim = 'Medium'\n",
        "    else:\n",
        "        traffic_multiplier_sim = 1.0\n",
        "        traffic_label_sim = 'Low'\n",
        "\n",
        "    sin_hour = np.sin(2 * np.pi * order_hour / 24)\n",
        "    cos_hour = np.cos(2 * np.pi * order_hour / 24)\n",
        "\n",
        "    # 3. Try to get live traffic via HERE API. If unavailable, fallback to simulation.\n",
        "    api_result = fetch_live_traffic_time(\n",
        "        NEW_ORDER_DATA['Restaurant_lat'], NEW_ORDER_DATA['Restaurant_lon'],\n",
        "        NEW_ORDER_DATA['Delivery_lat'], NEW_ORDER_DATA['Delivery_lon'],\n",
        "        HERE_API_KEY\n",
        "    )\n",
        "    estimated_travel_time_traffic_adjusted, base_travel_time_min_api = api_result\n",
        "\n",
        "    BASE_SPEED_KM_PER_MIN = 0.5  # 30 km/h baseline\n",
        "\n",
        "    if estimated_travel_time_traffic_adjusted is None:\n",
        "        base_travel_time_min = delivery_distance_km / BASE_SPEED_KM_PER_MIN\n",
        "        estimated_travel_time_traffic_adjusted = base_travel_time_min * traffic_multiplier_sim\n",
        "        traffic_density = traffic_label_sim\n",
        "    else:\n",
        "        traffic_ratio = estimated_travel_time_traffic_adjusted / base_travel_time_min_api\n",
        "        if traffic_ratio >= 1.5:\n",
        "            traffic_density = 'Jam'\n",
        "        elif traffic_ratio >= 1.25:\n",
        "            traffic_density = 'High'\n",
        "        elif traffic_ratio >= 1.05:\n",
        "            traffic_density = 'Medium'\n",
        "        else:\n",
        "            traffic_density = 'Low'\n",
        "\n",
        "    # --- Prediction DataFrame Construction (match ordering and raw categorical columns) ---\n",
        "    input_data_final = pd.DataFrame({\n",
        "        'delivery_distance_km': [delivery_distance_km],\n",
        "        'preparation_time_min': [NEW_ORDER_DATA['preparation_time_min']],\n",
        "        'restaurant_rating': [NEW_ORDER_DATA['restaurant_rating']],\n",
        "        'delivery_person_rating': [NEW_ORDER_DATA['delivery_person_rating']],\n",
        "        'Road_Traffic_Density': [traffic_density],      # categorical\n",
        "        'Weather_Condition': [weather_main],            # categorical\n",
        "        'sin_hour': [sin_hour],\n",
        "        'cos_hour': [cos_hour],\n",
        "        'current_temp_c': [temp if not np.isnan(temp) else 25.0]\n",
        "    })\n",
        "\n",
        "    # 4. Predict\n",
        "    try:\n",
        "        prediction_proba = model_pipeline.predict_proba(input_data_final)[:, 1][0] * 100\n",
        "    except Exception as e:\n",
        "        print(f\"Prediction Error: {e}\")\n",
        "        prediction_proba = 50.0\n",
        "\n",
        "    # 5. Output\n",
        "    print(f\"\\n--- Prediction Result ---\")\n",
        "    print(f\"Distance: {delivery_distance_km:.2f} km\")\n",
        "    print(f\"Estimated Traffic-Adjusted Travel Time: {estimated_travel_time_traffic_adjusted:.1f} min\")\n",
        "    print(f\"Current Traffic Density (categorical): {traffic_density}\")\n",
        "    print(f\"Weather: {weather_main}, temp: {temp}Â°C, wind_speed: {wind_speed}\")\n",
        "    print(f\"Probability of Being Late: {prediction_proba:.2f}%\")\n",
        "    if prediction_proba > 60:\n",
        "        print(\"Conclusion: High risk of late delivery (Predicted Late).\")\n",
        "    elif prediction_proba > 40:\n",
        "        print(\"Conclusion: Moderate risk of late delivery.\")\n",
        "    else:\n",
        "        print(\"Conclusion: Low risk of late delivery.\")\n",
        "\n",
        "\n",
        "# --- Cell 7: Execute the Full Pipeline ---\n",
        "\n",
        "# Step 1 & 2: Get Data and Features\n",
        "df_train, feature_list = get_or_create_dataset()\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# Step 3: Preprocessing Setup\n",
        "preprocessor = create_preprocessing_pipeline(feature_list)\n",
        "X_train, X_test, y_train, y_test = perform_preprocessing(df_train, feature_list, preprocessor)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# Step 4: Train, Evaluate, and Save Model\n",
        "trained_pipeline = train_and_evaluate_model(X_train, X_test, y_train, y_test, preprocessor)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# Step 5: Real-time Prediction Demonstration (using the trained model)\n",
        "create_real_time_dashboard(trained_pipeline, feature_list)\n",
        "\n",
        "# If running in Colab and you want to download the model file:\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('late_delivery_predictor_model.pkl')\n",
        "except Exception:\n",
        "    # Not running in Colab, ignore.\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "requirements = \"\"\"\n",
        "pandas>=1.5.0\n",
        "numpy>=1.25.0\n",
        "scikit-learn>=1.3.0\n",
        "xgboost>=1.7.6\n",
        "requests>=2.31.0\n",
        "joblib>=1.3.1\n",
        "streamlit>=1.26.1\n",
        "\"\"\"\n",
        "\n",
        "with open(\"requirements.txt\", \"w\") as f:\n",
        "    f.write(requirements)\n",
        "\n",
        "print(\"requirements.txt created successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjdQdHtE8jXp",
        "outputId": "0219792f-35af-4f72-e817-036698e9d60f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "requirements.txt created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app_code = \"\"\"\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from math import sin, cos, pi\n",
        "\n",
        "# Load model\n",
        "model_pipeline = joblib.load(\"late_delivery_predictor_model.pkl\")\n",
        "\n",
        "st.set_page_config(page_title=\"Food Delivery Delay Predictor\", layout=\"centered\")\n",
        "st.title(\"ðŸšš Food Delivery Delay Predictor\")\n",
        "\n",
        "st.markdown(\"Simulate a new delivery scenario:\")\n",
        "\n",
        "prep_time = st.slider(\"Preparation Time (min)\", 5, 60, 20)\n",
        "restaurant_rating = st.slider(\"Restaurant Rating\", 3.0, 5.0, 4.0)\n",
        "delivery_person_rating = st.slider(\"Delivery Person Rating\", 4.0, 5.0, 4.5)\n",
        "delivery_distance_km = st.slider(\"Delivery Distance (km)\", 0.1, 40.0, 5.0)\n",
        "order_hour = st.slider(\"Order Hour (0-23)\", 0, 23, 12)\n",
        "traffic_density = st.selectbox(\"Traffic Density\", [\"Low\", \"Medium\", \"High\", \"Jam\"])\n",
        "weather_condition = st.selectbox(\"Weather Condition\", [\"Clear\", \"Rainy\", \"Foggy\", \"Stormy\"])\n",
        "current_temp_c = st.slider(\"Current Temperature (Â°C)\", 10, 40, 25)\n",
        "\n",
        "sin_hour = sin(2 * pi * order_hour / 24)\n",
        "cos_hour = cos(2 * pi * order_hour / 24)\n",
        "\n",
        "input_df = pd.DataFrame({\n",
        "    'delivery_distance_km': [delivery_distance_km],\n",
        "    'preparation_time_min': [prep_time],\n",
        "    'restaurant_rating': [restaurant_rating],\n",
        "    'delivery_person_rating': [delivery_person_rating],\n",
        "    'Road_Traffic_Density': [traffic_density],\n",
        "    'Weather_Condition': [weather_condition],\n",
        "    'sin_hour': [sin_hour],\n",
        "    'cos_hour': [cos_hour],\n",
        "    'current_temp_c': [current_temp_c]\n",
        "})\n",
        "\n",
        "if st.button(\"Predict Delay\"):\n",
        "    proba = model_pipeline.predict_proba(input_df)[0][1] * 100\n",
        "    if proba > 60:\n",
        "        st.error(f\"âŒ High risk of late delivery ({proba:.2f}%)\")\n",
        "    elif proba > 40:\n",
        "        st.warning(f\"âš  Moderate risk of late delivery ({proba:.2f}%)\")\n",
        "    else:\n",
        "        st.success(f\"âœ… Low risk of late delivery ({proba:.2f}%)\")\n",
        "\"\"\"\n",
        "\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(app_code)\n",
        "\n",
        "print(\"app.py created successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZtMMTik9sWj",
        "outputId": "c7756285-a55d-4725-fb2a-32444f5cdfd7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "app.py created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save pipeline/model\n",
        "joblib.dump(trained_pipeline, \"late_delivery_predictor_model.pkl\")\n",
        "print(\"model.pkl saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "orRRAf81Ciq6",
        "outputId": "93a00290-a668-441c-ea11-bc6591319ef8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'trained_pipeline' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1862763321.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Save pipeline/model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"late_delivery_predictor_model.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model.pkl saved successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trained_pipeline' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn==1.3.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "aO7eX5OZCrqQ",
        "outputId": "6b0dad5c-181d-49f1-b10b-21b115e769f4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn==1.3.2\n",
            "  Downloading scikit_learn-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting numpy<2.0,>=1.17.3 (from scikit-learn==1.3.2)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.2) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.2) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.2) (3.6.0)\n",
            "Downloading scikit_learn-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scikit-learn\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "cuml-cu12 25.10.0 requires scikit-learn>=1.4, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "imbalanced-learn 0.14.0 requires scikit-learn<2,>=1.4.2, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4 scikit-learn-1.3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "sklearn"
                ]
              },
              "id": "8086aa10c0a64d86b46dcde7a2462703"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn==1.3.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1In6u6rE1TY",
        "outputId": "9d634ce4-c979-4179-e82c-677a32d8d64b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn==1.3.2 in /usr/local/lib/python3.12/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.2) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.2) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.2) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.3.2) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(trained_pipeline, \"model_new.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl2ufnS4FdNP",
        "outputId": "f47de86b-be84-46ca-aaca-c05f53a979fa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model_new.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JilRDh4eFo76"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}