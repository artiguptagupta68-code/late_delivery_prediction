{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L4RaufNV8ifL",
        "outputId": "ba652e5d-fc46-4647-8bd9-864b29d312a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.7.2)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Found existing installation: scikit-learn 1.7.2\n",
            "Uninstalling scikit-learn-1.7.2:\n",
            "  Successfully uninstalled scikit-learn-1.7.2\n",
            "Collecting scikit-learn==1.7.2\n",
            "  Using cached scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.7.2) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.7.2) (3.6.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Using cached scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
            "Installing collected packages: scikit-learn\n",
            "Successfully installed scikit-learn-1.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              },
              "id": "104769a595d44e53bbdcdfa21cf1835e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment setup check completed. Required libraries are installed.\n",
            "28.6139,77.209\n",
            "... Loading or creating simulated historical dataset ...\n",
            "Dataset created with 500 samples. Target variable 'is_late' distribution:\n",
            "is_late\n",
            "1    0.5\n",
            "0    0.5\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "==================================================\n",
            "\n",
            "Preprocessing pipeline (Scaling + One-Hot Encoding) created.\n",
            "Data split: Train size: 400, Test size: 100\n",
            "\n",
            "==================================================\n",
            "\n",
            "... Training XGBoost model ...\n",
            "Training completed in 0.08 seconds.\n",
            "\n",
            "--- Model Evaluation (Test Set) ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.58      0.57        50\n",
            "           1       0.57      0.56      0.57        50\n",
            "\n",
            "    accuracy                           0.57       100\n",
            "   macro avg       0.57      0.57      0.57       100\n",
            "weighted avg       0.57      0.57      0.57       100\n",
            "\n",
            "ROC AUC Score: 0.5356\n",
            "Model saved as 'late_delivery_predictor_model.pkl'.\n",
            "\n",
            "==================================================\n",
            "\n",
            "\n",
            "--- Conceptual Streamlit Dashboard Code (omitted) ---\n",
            "To run the full dashboard, save the Streamlit app separately (app.py).\n",
            "\n",
            "--- Real-Time Prediction Demonstration ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1874625372.py:172: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  'Order_Placed_Time': pd.to_datetime(pd.date_range('2025-01-01', periods=500, freq='4H')),\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [14:26:57] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weather fetched successfully: Clear, 20.15¬∞C\n",
            "Live traffic data successfully retrieved from HERE API.\n",
            "\n",
            "--- Prediction Result ---\n",
            "Distance: 14.79 km\n",
            "Estimated Traffic-Adjusted Travel Time: 52.5 min\n",
            "Current Traffic Density (categorical): Jam\n",
            "Weather: Clear, temp: 20.15¬∞C, wind_speed: 1.78\n",
            "Probability of Being Late: 82.36%\n",
            "Conclusion: High risk of late delivery (Predicted Late).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# --- Cell 1: Setup and Requirements ---\n",
        "\n",
        "!pip install pandas numpy scikit-learn xgboost requests joblib\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "import joblib\n",
        "import time\n",
        "from datetime import datetime\n",
        "!pip uninstall -y scikit-learn\n",
        "!pip install scikit-learn==1.7.2 xgboost pandas numpy joblib requests\n",
        "\n",
        "# --- Configuration (UPDATE THIS!) ---\n",
        "# You need a key from OpenWeatherMap or a similar service to fetch real-time data.\n",
        "WEATHER_API_KEY = \"5197fc88f5f846ee7566eb28d403c91f\"\n",
        "\n",
        "# Added from app.py: HERE API key and placeholder check\n",
        "HERE_API_KEY = \"9JI9eOC0auXHPTmtQ5SohrGPp4WjOaq90TRCjfa-Czw\"\n",
        "PLACEHOLDER_CHECK = \"PASTE_YOUR_API_KEY_HERE\"\n",
        "\n",
        "THRESHOLD_MIN = 10  # Delivery is \"Late\" if actual time > estimated time + THRESHOLD_MIN\n",
        "\n",
        "def setup_environment():\n",
        "    \"\"\"Confirms environment setup.\"\"\"\n",
        "    print(\"Environment setup check completed. Required libraries are installed.\")\n",
        "\n",
        "# Run setup\n",
        "setup_environment()\n",
        "\n",
        "\n",
        "# --- Cell 2: Helper Functions ---\n",
        "\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    \"\"\"Calculate the great circle distance in km between two points on the earth.\"\"\"\n",
        "    R = 6371  # Earth radius in kilometers\n",
        "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
        "    dlon = lon2 - lon1\n",
        "    dlat = lat2 - lat1\n",
        "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
        "    c = 2 * np.arcsin(np.sqrt(a))\n",
        "    return R * c\n",
        "\n",
        "def fetch_realtime_weather(latitude, longitude, api_key):\n",
        "    \"\"\"Fetches real-time weather data for a given location using OpenWeatherMap API.\n",
        "    Returns (temp, weather_main, wind_speed). Uses fallback on failure.\"\"\"\n",
        "    if not api_key or api_key.strip() == \"\" or api_key == \"YOUR_OPENWEATHERMAP_API_KEY\":\n",
        "        print(\"Warning: Weather API Key missing or placeholder. Using fallback weather values.\")\n",
        "        return 25.0, 'Clear', 5.0  # Return fallback values for simulation\n",
        "\n",
        "    try:\n",
        "        url = f\"http://api.openweathermap.org/data/2.5/weather?lat={latitude}&lon={longitude}&appid={api_key}&units=metric\"\n",
        "        response = requests.get(url, timeout=6)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        temp = data['main']['temp']\n",
        "        weather_main = data['weather'][0]['main']\n",
        "        wind_speed = data['wind'].get('speed', np.nan)\n",
        "\n",
        "        print(f\"Weather fetched successfully: {weather_main}, {temp}¬∞C\")\n",
        "        return temp, weather_main, wind_speed\n",
        "\n",
        "    except requests.exceptions.HTTPError as e:\n",
        "        # If auth error or other HTTP errors occur, fallback\n",
        "        try:\n",
        "            status = response.status_code\n",
        "            print(f\"Weather API HTTP Error ({status}): {e}. Using fallback.\")\n",
        "        except Exception:\n",
        "            print(f\"Weather API HTTP Error: {e}. Using fallback.\")\n",
        "        return np.nan, 'Unknown', np.nan\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching weather data: {e}. Using fallback.\")\n",
        "        return np.nan, 'Unknown', np.nan\n",
        "\n",
        "\n",
        "def fetch_coordinates(location_name, api_key):\n",
        "    \"\"\"Forward geocoding: returns (lat, lon, display_name) using OpenWeatherMap geocoding endpoint.\n",
        "    If not possible, returns (None, None, None).\"\"\"\n",
        "    if not api_key or not location_name:\n",
        "        return None, None, None\n",
        "    try:\n",
        "        url = f\"http://api.openweathermap.org/geo/1.0/direct?q={location_name}&limit=1&appid={api_key}\"\n",
        "        response = requests.get(url, timeout=5)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if data:\n",
        "            loc = data[0]\n",
        "            lat = loc.get('lat')\n",
        "            lon = loc.get('lon')\n",
        "            display_name = f\"{loc.get('name', 'N/A')}, {loc.get('country', 'N/A')}\"\n",
        "            return lat, lon, display_name\n",
        "        else:\n",
        "            print(f\"Warning: Could not find coordinates for: {location_name}\")\n",
        "            return None, None, None\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Geocoding Error: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "\n",
        "def fetch_live_traffic_time(rest_lat, rest_lon, del_lat, del_lon, api_key):\n",
        "    \"\"\"\n",
        "    Call HERE Routing API with traffic enabled (if API key present).\n",
        "    Returns (estimated_travel_time_traffic_adjusted_min, base_travel_time_min) in minutes.\n",
        "    If API unavailable or key missing/placeholder, returns (None, None) to indicate fallback simulation should be used.\n",
        "    \"\"\"\n",
        "    if not api_key or api_key == PLACEHOLDER_CHECK:\n",
        "        # No real traffic available; caller should fallback to simulation\n",
        "        return None, None\n",
        "\n",
        "    try:\n",
        "        url = \"https://router.hereapi.com/v8/routes\"\n",
        "        origin_coords = f\"{rest_lat},{rest_lon}\"\n",
        "        destination_coords = f\"{del_lat},{del_lon}\"\n",
        "        params = {\n",
        "            'transportMode': 'car',\n",
        "            'origin': origin_coords,\n",
        "            'destination': destination_coords,\n",
        "            'routingMode': 'fast',\n",
        "            'trafficMode': 'realtime',\n",
        "            'return': 'summary',\n",
        "            'apiKey': api_key\n",
        "        }\n",
        "        response = requests.get(url, params=params, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        if data.get('routes') and data['routes'][0].get('sections'):\n",
        "            summary = data['routes'][0]['sections'][0]['summary']\n",
        "            traffic_duration_sec = summary.get('duration')\n",
        "            base_duration_sec = summary.get('baseDuration')\n",
        "            if traffic_duration_sec is None or base_duration_sec is None:\n",
        "                print(\"HERE API response missing duration data. Falling back to simulation.\")\n",
        "                return None, None\n",
        "            traffic_duration_min = traffic_duration_sec / 60.0\n",
        "            base_travel_time_min = base_duration_sec / 60.0\n",
        "            print(\"Live traffic data successfully retrieved from HERE API.\")\n",
        "            return traffic_duration_min, base_travel_time_min\n",
        "        else:\n",
        "            print(\"HERE API failed to find route. Falling back to simulation.\")\n",
        "            return None, None\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"HERE API Connection Error: {e}. Falling back to simulation.\")\n",
        "        return None, None\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing HERE response: {e}. Falling back to simulation.\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "# --- Cell 3: Dataset Creation and Feature Engineering ---\n",
        "\n",
        "def get_or_create_dataset():\n",
        "    \"\"\"Simulates loading and initial feature engineering on a historical dataset.\"\"\"\n",
        "    print(\"... Loading or creating simulated historical dataset ...\")\n",
        "\n",
        "    # 1. Simulate Historical Data\n",
        "    np.random.seed(42)  # For reproducibility\n",
        "    data = {\n",
        "        'Order_ID': range(500),  # Increased sample size\n",
        "        'Restaurant_lat': np.random.uniform(28.5, 28.7, 500),\n",
        "        'Restaurant_lon': np.random.uniform(77.1, 77.3, 500),\n",
        "        'Delivery_lat': np.random.uniform(28.5, 28.7, 500),\n",
        "        'Delivery_lon': np.random.uniform(77.1, 77.3, 500),\n",
        "        'Order_Placed_Time': pd.to_datetime(pd.date_range('2025-01-01', periods=500, freq='4H')),\n",
        "        'Initial_Estimate_Min': np.random.randint(25, 45, 500),\n",
        "        'Actual_Delivery_Time_Min': np.random.randint(20, 70, 500),\n",
        "        'preparation_time_min': np.random.randint(10, 30, 500),\n",
        "        'restaurant_rating': np.random.uniform(3.0, 5.0, 500).round(1),\n",
        "        'delivery_person_rating': np.random.uniform(4.0, 5.0, 500).round(1),\n",
        "        'Road_Traffic_Density': np.random.choice(['Low', 'Medium', 'High', 'Jam'], 500, p=[0.4, 0.3, 0.2, 0.1]),\n",
        "        'Weather_Condition': np.random.choice(['Clear', 'Rainy', 'Foggy', 'Stormy'], 500, p=[0.7, 0.2, 0.05, 0.05])\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # 2. Feature Engineering\n",
        "    df['delivery_distance_km'] = haversine(\n",
        "        df['Restaurant_lat'], df['Restaurant_lon'],\n",
        "        df['Delivery_lat'], df['Delivery_lon']\n",
        "    )\n",
        "\n",
        "    # Time-based features\n",
        "    df['order_hour'] = df['Order_Placed_Time'].dt.hour\n",
        "    df['day_of_week'] = df['Order_Placed_Time'].dt.day_name()\n",
        "\n",
        "    # Cyclic features for hour\n",
        "    df['sin_hour'] = np.sin(2 * np.pi * df['order_hour'] / 24)\n",
        "    df['cos_hour'] = np.cos(2 * np.pi * df['order_hour'] / 24)\n",
        "\n",
        "    # Target Variable\n",
        "    df['is_late'] = np.where(\n",
        "        df['Actual_Delivery_Time_Min'] > (df['Initial_Estimate_Min'] + THRESHOLD_MIN),\n",
        "        1,\n",
        "        0\n",
        "    )\n",
        "\n",
        "    # Add simulated weather for training data (as historical data won't use the live API)\n",
        "    df['current_temp_c'] = np.random.uniform(15, 35, 500)\n",
        "\n",
        "    final_features = [\n",
        "        'delivery_distance_km', 'preparation_time_min', 'restaurant_rating',\n",
        "        'delivery_person_rating', 'Road_Traffic_Density', 'Weather_Condition',\n",
        "        'sin_hour', 'cos_hour'\n",
        "    ]\n",
        "\n",
        "    df_train = df[final_features + ['current_temp_c', 'is_late']].copy()\n",
        "\n",
        "    print(f\"Dataset created with {len(df_train)} samples. Target variable 'is_late' distribution:\")\n",
        "    print(df_train['is_late'].value_counts(normalize=True))\n",
        "    return df_train, final_features\n",
        "\n",
        "\n",
        "# --- Cell 4: Preprocessing Functions ---\n",
        "\n",
        "def create_preprocessing_pipeline(feature_list):\n",
        "    \"\"\"Creates a scikit-learn ColumnTransformer for preprocessing.\"\"\"\n",
        "\n",
        "    numeric_features = [\n",
        "        'delivery_distance_km', 'preparation_time_min', 'restaurant_rating',\n",
        "        'delivery_person_rating', 'current_temp_c', 'sin_hour', 'cos_hour'\n",
        "    ]\n",
        "\n",
        "    categorical_features = [\n",
        "        'Road_Traffic_Density', 'Weather_Condition'\n",
        "    ]\n",
        "\n",
        "    # Create preprocessing steps\n",
        "    numeric_transformer = Pipeline(steps=[\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "\n",
        "    # Combine transformers\n",
        "    # Only include features present in feature_list (plus current_temp_c)\n",
        "    num_cols = [f for f in numeric_features if (f in feature_list) or (f == 'current_temp_c')]\n",
        "    cat_cols = [f for f in categorical_features if f in feature_list]\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, num_cols),\n",
        "            ('cat', categorical_transformer, cat_cols)\n",
        "        ],\n",
        "        remainder='passthrough'\n",
        "    )\n",
        "\n",
        "    print(\"Preprocessing pipeline (Scaling + One-Hot Encoding) created.\")\n",
        "    return preprocessor  # FIX: return the actual preprocessor object\n",
        "\n",
        "\n",
        "def perform_preprocessing(df_train, feature_list, preprocessor):\n",
        "    \"\"\"Splits data and prepares for the full pipeline.\"\"\"\n",
        "\n",
        "    # Include 'current_temp_c' in X for training as it's a numeric feature\n",
        "    X = df_train[feature_list + ['current_temp_c']].copy()\n",
        "    y = df_train['is_late']\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    print(f\"Data split: Train size: {len(X_train)}, Test size: {len(X_test)}\")\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "# --- Cell 5: Model Training, Evaluation, and Saving ---\n",
        "\n",
        "def train_and_evaluate_model(X_train, X_test, y_train, y_test, preprocessor):\n",
        "    \"\"\"Defines, trains, and evaluates the final ML pipeline.\"\"\"\n",
        "\n",
        "    # Model Choice: XGBoost Hyperparameters\n",
        "    XGB_PARAMS = {\n",
        "        'objective': 'binary:logistic',\n",
        "        'n_estimators': 300,\n",
        "        'learning_rate': 0.05,\n",
        "        'max_depth': 5,\n",
        "        'subsample': 0.7,\n",
        "        'colsample_bytree': 0.7,\n",
        "        'random_state': 42,\n",
        "        'use_label_encoder': False,\n",
        "        'eval_metric': 'logloss'\n",
        "    }\n",
        "\n",
        "    model = XGBClassifier(**XGB_PARAMS)\n",
        "\n",
        "    # Create the full ML pipeline\n",
        "    full_pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', model)\n",
        "    ])\n",
        "\n",
        "    print(\"... Training XGBoost model ...\")\n",
        "    start_time = time.time()\n",
        "    full_pipeline.fit(X_train, y_train)\n",
        "    end_time = time.time()\n",
        "    print(f\"Training completed in {end_time - start_time:.2f} seconds.\")\n",
        "\n",
        "    # Evaluation\n",
        "    y_pred = full_pipeline.predict(X_test)\n",
        "    y_proba = full_pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    print(\"\\n--- Model Evaluation (Test Set) ---\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(f\"ROC AUC Score: {roc_auc_score(y_test, y_proba):.4f}\")\n",
        "\n",
        "    # Save the model\n",
        "    joblib.dump(full_pipeline, 'late_delivery_predictor_model.pkl')\n",
        "    print(\"Model saved as 'late_delivery_predictor_model.pkl'.\")\n",
        "\n",
        "    return full_pipeline\n",
        "\n",
        "\n",
        "# --- Cell 6: Real-Time Dashboard (Conceptual & Demonstration) ---\n",
        "\n",
        "def create_real_time_dashboard(model_pipeline, features):\n",
        "    \"\"\"\n",
        "    Provides the conceptual code for the Streamlit dashboard and demonstrates a real-time prediction using the saved model.\n",
        "    This function performs a real-time prediction demonstration (not a full Streamlit app).\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n--- Conceptual Streamlit Dashboard Code (omitted) ---\")\n",
        "    print(\"To run the full dashboard, save the Streamlit app separately (app.py).\")\n",
        "    print(\"\\n--- Real-Time Prediction Demonstration ---\")\n",
        "\n",
        "    # 1. Define a New Order (Input Data)\n",
        "    NEW_ORDER_DATA = {\n",
        "        'Restaurant_lat': 28.60,\n",
        "        'Restaurant_lon': 77.15,\n",
        "        'Delivery_lat': 28.70,\n",
        "        'Delivery_lon': 77.25,\n",
        "        'preparation_time_min': 25,\n",
        "        'restaurant_rating': 4.2,\n",
        "        'delivery_person_rating': 4.9,\n",
        "    }\n",
        "\n",
        "    # 2. Feature Engineering\n",
        "    current_time = pd.Timestamp.now(tz='Asia/Kolkata')\n",
        "    order_hour = current_time.hour\n",
        "\n",
        "    delivery_distance_km = haversine(\n",
        "        NEW_ORDER_DATA['Restaurant_lat'], NEW_ORDER_DATA['Restaurant_lon'],\n",
        "        NEW_ORDER_DATA['Delivery_lat'], NEW_ORDER_DATA['Delivery_lon']\n",
        "    )\n",
        "\n",
        "    # Simulate Real-time Dynamic Features\n",
        "    temp, weather_main, wind_speed = fetch_realtime_weather(\n",
        "        NEW_ORDER_DATA['Delivery_lat'],\n",
        "        NEW_ORDER_DATA['Delivery_lon'],\n",
        "        WEATHER_API_KEY\n",
        "    )\n",
        "\n",
        "    # Traffic Density Simulation based on time (for demonstration)\n",
        "    # Use multipliers and labels adopted from app.py\n",
        "    if 17 <= order_hour <= 21:\n",
        "        traffic_multiplier_sim = 1.67\n",
        "        traffic_label_sim = 'Jam'\n",
        "    elif 12 <= order_hour <= 14:\n",
        "        traffic_multiplier_sim = 1.33\n",
        "        traffic_label_sim = 'High'\n",
        "    elif 8 <= order_hour <= 10:\n",
        "        traffic_multiplier_sim = 1.18\n",
        "        traffic_label_sim = 'Medium'\n",
        "    else:\n",
        "        traffic_multiplier_sim = 1.0\n",
        "        traffic_label_sim = 'Low'\n",
        "\n",
        "    sin_hour = np.sin(2 * np.pi * order_hour / 24)\n",
        "    cos_hour = np.cos(2 * np.pi * order_hour / 24)\n",
        "\n",
        "    # 3. Try to get live traffic via HERE API. If unavailable, fallback to simulation.\n",
        "    api_result = fetch_live_traffic_time(\n",
        "        NEW_ORDER_DATA['Restaurant_lat'], NEW_ORDER_DATA['Restaurant_lon'],\n",
        "        NEW_ORDER_DATA['Delivery_lat'], NEW_ORDER_DATA['Delivery_lon'],\n",
        "        HERE_API_KEY\n",
        "    )\n",
        "    estimated_travel_time_traffic_adjusted, base_travel_time_min_api = api_result\n",
        "\n",
        "    BASE_SPEED_KM_PER_MIN = 0.5  # 30 km/h baseline\n",
        "\n",
        "    if estimated_travel_time_traffic_adjusted is None:\n",
        "        base_travel_time_min = delivery_distance_km / BASE_SPEED_KM_PER_MIN\n",
        "        estimated_travel_time_traffic_adjusted = base_travel_time_min * traffic_multiplier_sim\n",
        "        traffic_density = traffic_label_sim\n",
        "    else:\n",
        "        traffic_ratio = estimated_travel_time_traffic_adjusted / base_travel_time_min_api\n",
        "        if traffic_ratio >= 1.5:\n",
        "            traffic_density = 'Jam'\n",
        "        elif traffic_ratio >= 1.25:\n",
        "            traffic_density = 'High'\n",
        "        elif traffic_ratio >= 1.05:\n",
        "            traffic_density = 'Medium'\n",
        "        else:\n",
        "            traffic_density = 'Low'\n",
        "\n",
        "    # --- Prediction DataFrame Construction (match ordering and raw categorical columns) ---\n",
        "    input_data_final = pd.DataFrame({\n",
        "        'delivery_distance_km': [delivery_distance_km],\n",
        "        'preparation_time_min': [NEW_ORDER_DATA['preparation_time_min']],\n",
        "        'restaurant_rating': [NEW_ORDER_DATA['restaurant_rating']],\n",
        "        'delivery_person_rating': [NEW_ORDER_DATA['delivery_person_rating']],\n",
        "        'Road_Traffic_Density': [traffic_density],      # categorical\n",
        "        'Weather_Condition': [weather_main],            # categorical\n",
        "        'sin_hour': [sin_hour],\n",
        "        'cos_hour': [cos_hour],\n",
        "        'current_temp_c': [temp if not np.isnan(temp) else 25.0]\n",
        "    })\n",
        "\n",
        "    # 4. Predict\n",
        "    try:\n",
        "        prediction_proba = model_pipeline.predict_proba(input_data_final)[:, 1][0] * 100\n",
        "    except Exception as e:\n",
        "        print(f\"Prediction Error: {e}\")\n",
        "        prediction_proba = 50.0\n",
        "\n",
        "    # 5. Output\n",
        "    print(f\"\\n--- Prediction Result ---\")\n",
        "    print(f\"Distance: {delivery_distance_km:.2f} km\")\n",
        "    print(f\"Estimated Traffic-Adjusted Travel Time: {estimated_travel_time_traffic_adjusted:.1f} min\")\n",
        "    print(f\"Current Traffic Density (categorical): {traffic_density}\")\n",
        "    print(f\"Weather: {weather_main}, temp: {temp}¬∞C, wind_speed: {wind_speed}\")\n",
        "    print(f\"Probability of Being Late: {prediction_proba:.2f}%\")\n",
        "    if prediction_proba > 60:\n",
        "        print(\"Conclusion: High risk of late delivery (Predicted Late).\")\n",
        "    elif prediction_proba > 40:\n",
        "        print(\"Conclusion: Moderate risk of late delivery.\")\n",
        "    else:\n",
        "        print(\"Conclusion: Low risk of late delivery.\")\n",
        "\n",
        "        import requests\n",
        "\n",
        "def get_location_name(lat, lon):\n",
        "    \"\"\"\n",
        "    Returns a human-readable location name from latitude and longitude.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        url = \"https://nominatim.openstreetmap.org/reverse\"\n",
        "        params = {\n",
        "            'lat': lat,\n",
        "            'lon': lon,\n",
        "            'format': 'json',\n",
        "            'addressdetails': 1\n",
        "        }\n",
        "        response = requests.get(url, params=params)\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            return data.get('display_name', f\"{lat},{lon}\")\n",
        "        else:\n",
        "            return f\"{lat},{lon}\"\n",
        "    except Exception as e:\n",
        "        print(f\"Reverse geocoding error: {e}\")\n",
        "        return f\"{lat},{lon}\"\n",
        "\n",
        "# Example\n",
        "lat, lon = 28.6139, 77.2090\n",
        "print(get_location_name(lat, lon))\n",
        "\n",
        "\n",
        "# --- Cell 7: Execute the Full Pipeline ---\n",
        "\n",
        "# Step 1 & 2: Get Data and Features\n",
        "df_train, feature_list = get_or_create_dataset()\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# Step 3: Preprocessing Setup\n",
        "preprocessor = create_preprocessing_pipeline(feature_list)\n",
        "X_train, X_test, y_train, y_test = perform_preprocessing(df_train, feature_list, preprocessor)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# Step 4: Train, Evaluate, and Save Model\n",
        "trained_pipeline = train_and_evaluate_model(X_train, X_test, y_train, y_test, preprocessor)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# Step 5: Real-time Prediction Demonstration (using the trained model)\n",
        "create_real_time_dashboard(trained_pipeline, feature_list)\n",
        "\n",
        "# If running in Colab and you want to download the model file:\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('model.pkl')\n",
        "except Exception:\n",
        "    # Not running in Colab, ignore.\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjdQdHtE8jXp",
        "outputId": "cf10c5c3-0050-4e3c-b145-7d0ebd99d0dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "requirements.txt created successfully!\n"
          ]
        }
      ],
      "source": [
        "requirements = \"\"\"\n",
        "scikit-learn==1.7.2\n",
        "xgboost\n",
        "pandas\n",
        "numpy\n",
        "joblib\n",
        "requests\n",
        "streamlit\n",
        "\"\"\"\n",
        "\n",
        "with open(\"requirements.txt\", \"w\") as f:\n",
        "    f.write(requirements)\n",
        "\n",
        "print(\"requirements.txt created successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZtMMTik9sWj",
        "outputId": "f8de6b3e-feba-4abe-f215-2597d41551ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.51.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.11.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.28.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2Tini63NMQPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae374fa9-bb68-4b5f-e901-6eb5f3a4f542"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "MODEL_PATH = \"late_delivery_predictor_model.pkl\"\n",
        "\n",
        "try:\n",
        "    model_pipeline = joblib.load(MODEL_PATH)\n",
        "except Exception as e:\n",
        "    st.error(f\"‚ùå Model could NOT be loaded!\\nError: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "st.success(\"Model loaded successfully ‚úî\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import requests\n",
        "from datetime import datetime\n",
        "import math\n",
        "# Load Model\n",
        "# -------------------------\n",
        "MODEL_PATH = \"late_delivery_predictor_model.pkl\"\n",
        "\n",
        "try:\n",
        "    model_pipeline = joblib.load(MODEL_PATH)\n",
        "except Exception as e:\n",
        "    st.error(f\"‚ùå Model could NOT be loaded!\\nError: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "st.success(\"Model loaded successfully ‚úî\")\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# API Keys (YOUR keys)\n",
        "# -------------------------\n",
        "WEATHER_API_KEY = \"YOUR_OPENWEATHERMAP_KEY\"\n",
        "HERE_API_KEY = \"YOUR_HERE_API_KEY\"\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Helper Functions\n",
        "# -------------------------\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    R = 6371\n",
        "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
        "    a = (\n",
        "        np.sin((lat2 - lat1) / 2) ** 2\n",
        "        + np.cos(lat1) * np.cos(lat2) * np.sin((lon2 - lon1) / 2) ** 2\n",
        "    )\n",
        "    return R * 2 * np.arcsin(np.sqrt(a))\n",
        "\n",
        "\n",
        "def fetch_realtime_weather(lat, lon):\n",
        "    if WEATHER_API_KEY == \"YOUR_OPENWEATHERMAP_KEY\":\n",
        "        return 25.0, \"Clear\", 4.0\n",
        "\n",
        "    try:\n",
        "        url = f\"http://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={WEATHER_API_KEY}&units=metric\"\n",
        "        r = requests.get(url, timeout=5)\n",
        "        data = r.json()\n",
        "\n",
        "        temp = data[\"main\"][\"temp\"]\n",
        "        weather_main = data[\"weather\"][0][\"main\"]\n",
        "        wind = data[\"wind\"][\"speed\"]\n",
        "\n",
        "        return temp, weather_main, wind\n",
        "\n",
        "    except:\n",
        "        return 25.0, \"Clear\", 4.0\n",
        "\n",
        "\n",
        "def fetch_live_traffic_time(rest_lat, rest_lon, del_lat, del_lon):\n",
        "    if HERE_API_KEY == \"YOUR_HERE_API_KEY\":\n",
        "        return None, None\n",
        "\n",
        "    try:\n",
        "        url = \"https://router.hereapi.com/v8/routes\"\n",
        "        params = {\n",
        "            \"transportMode\": \"car\",\n",
        "            \"origin\": f\"{rest_lat},{rest_lon}\",\n",
        "            \"destination\": f\"{del_lat},{del_lon}\",\n",
        "            \"routingMode\": \"fast\",\n",
        "            \"trafficMode\": \"realtime\",\n",
        "            \"return\": \"summary\",\n",
        "            \"apiKey\": HERE_API_KEY,\n",
        "        }\n",
        "        r = requests.get(url, params=params, timeout=8)\n",
        "        data = r.json()\n",
        "        summary = data[\"routes\"][0][\"sections\"][0][\"summary\"]\n",
        "\n",
        "        return summary[\"duration\"] / 60, summary[\"baseDuration\"] / 60\n",
        "\n",
        "    except:\n",
        "        return None, None\n",
        "        import requests\n",
        "\n",
        "def get_location_name(lat, lon):\n",
        "    \"\"\"\n",
        "    Returns a human-readable location name from latitude and longitude.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        url = \"https://nominatim.openstreetmap.org/reverse\"\n",
        "        params = {\n",
        "            'lat': lat,\n",
        "            'lon': lon,\n",
        "            'format': 'json',\n",
        "            'addressdetails': 1\n",
        "        }\n",
        "        response = requests.get(url, params=params)\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            return data.get('display_name', f\"{lat},{lon}\")\n",
        "        else:\n",
        "            return f\"{lat},{lon}\"\n",
        "    except Exception as e:\n",
        "        print(f\"Reverse geocoding error: {e}\")\n",
        "        return f\"{lat},{lon}\"\n",
        "\n",
        "# Example\n",
        "lat, lon = 28.6139, 77.2090\n",
        "print(get_location_name(lat, lon))\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Streamlit UI\n",
        "# -------------------------\n",
        "st.title(\"üöö Late Delivery Prediction Dashboard\")\n",
        "st.markdown(\"Enter details to predict whether a delivery will be **late or on time**.\")\n",
        "\n",
        "col1, col2 = st.columns(2)\n",
        "\n",
        "with col1:\n",
        "    rest_lat = st.number_input(\"Restaurant Latitude\", 28.50, 28.80, 28.60)\n",
        "    rest_lon = st.number_input(\"Restaurant Longitude\", 77.10, 77.40, 77.20)\n",
        "    prep_time = st.slider(\"Preparation Time (min)\", 5, 60, 20)\n",
        "    rest_rating = st.slider(\"Restaurant Rating\", 1.0, 5.0, 4.2)\n",
        "\n",
        "with col2:\n",
        "    del_lat = st.number_input(\"Delivery Latitude\", 28.50, 28.80, 28.70)\n",
        "    del_lon = st.number_input(\"Delivery Longitude\", 77.10, 77.40, 77.25)\n",
        "    del_rating = st.slider(\"Delivery Person Rating\", 1.0, 5.0, 4.9)\n",
        "\n",
        "\n",
        "if st.button(\"Predict Late Delivery üöÄ\"):\n",
        "\n",
        "    distance = haversine(rest_lat, rest_lon, del_lat, del_lon)\n",
        "    now = datetime.now()\n",
        "    hr = now.hour\n",
        "    sin_hr = math.sin(2 * math.pi * hr / 24)\n",
        "    cos_hr = math.cos(2 * math.pi * hr / 24)\n",
        "\n",
        "    temp, weather_main, wind = fetch_realtime_weather(del_lat, del_lon)\n",
        "\n",
        "    t_live, t_base = fetch_live_traffic_time(rest_lat, rest_lon, del_lat, del_lon)\n",
        "\n",
        "    # --- Fallback traffic simulation ---\n",
        "    if t_live is None:\n",
        "        if 17 <= hr <= 21:\n",
        "            traffic_density = \"Jam\"\n",
        "        elif 12 <= hr <= 14:\n",
        "            traffic_density = \"High\"\n",
        "        elif 8 <= hr <= 10:\n",
        "            traffic_density = \"Medium\"\n",
        "        else:\n",
        "            traffic_density = \"Low\"\n",
        "    else:\n",
        "        ratio = t_live / t_base\n",
        "        if ratio >= 1.5:\n",
        "            traffic_density = \"Jam\"\n",
        "        elif ratio >= 1.25:\n",
        "            traffic_density = \"High\"\n",
        "        elif ratio >= 1.05:\n",
        "            traffic_density = \"Medium\"\n",
        "        else:\n",
        "            traffic_density = \"Low\"\n",
        "\n",
        "    # --- Model Input ---\n",
        "    input_df = pd.DataFrame({\n",
        "        \"delivery_distance_km\": [distance],\n",
        "        \"preparation_time_min\": [prep_time],\n",
        "        \"restaurant_rating\": [rest_rating],\n",
        "        \"delivery_person_rating\": [del_rating],\n",
        "        \"Road_Traffic_Density\": [traffic_density],\n",
        "        \"Weather_Condition\": [weather_main],\n",
        "        \"sin_hour\": [sin_hr],\n",
        "        \"cos_hour\": [cos_hr],\n",
        "        \"current_temp_c\": [temp],\n",
        "    })\n",
        "\n",
        "    try:\n",
        "        late_prob = model_pipeline.predict_proba(input_df)[0][1] * 100\n",
        "        st.subheader(f\"üìä Late Delivery Probability: **{late_prob:.2f}%**\")\n",
        "\n",
        "        if late_prob > 60:\n",
        "            st.error(\"‚ùó High Risk of Being LATE\")\n",
        "        elif late_prob > 40:\n",
        "            st.warning(\"‚ö†Ô∏è Medium Risk of Late\")\n",
        "        else:\n",
        "            st.success(\"‚úÖ Low Risk of Late Delivery\")\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Prediction Failed: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQgJH3-ypORy",
        "outputId": "dc24a4e3-8508-43ac-c7b5-62a7e1988b62"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"requirements.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "iJrtY3rDpvc1",
        "outputId": "1dadf77d-8aac-4d80-c6e4-0d048c9d253f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_55d9c908-1da9-417b-bd2d-e5117528a27f\", \"requirements.txt\", 68)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "sklearn.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IQG8UbElp-71",
        "outputId": "efe9af3d-7fba-48e3-ca96-58d6a2c4415e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.6.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y scikit-learn\n",
        "!pip install scikit-learn==1.7.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "ZST0R2XMxPWY",
        "outputId": "2075c49a-0a25-436a-f7af-0a617ceb15db"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: scikit-learn 1.6.1\n",
            "Uninstalling scikit-learn-1.6.1:\n",
            "  Successfully uninstalled scikit-learn-1.6.1\n",
            "Collecting scikit-learn==1.7.2\n",
            "  Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.7.2) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.7.2) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.7.2) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.7.2) (3.6.0)\n",
            "Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "Successfully installed scikit-learn-1.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              },
              "id": "993edcd97a584aa6be8ae55c45a61aba"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dGsSN2Cq0ZAx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}